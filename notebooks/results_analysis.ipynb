{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "def calculate_mean_std(df_names, dfs):\n",
    "    perf_train, perf_fair = [], []\n",
    "\n",
    "    for df_name, df in zip(df_names, dfs):\n",
    "        df_train = df[df['data'] == 'train_cont_ord_cat'].drop(columns=['data'])\n",
    "        df_fair = df[df['data'] == 'fair_cont_ord_cat'].drop(columns=['data'])\n",
    "        \n",
    "        df_train_mean = df_train.mean()\n",
    "        df_train_std = df_train.std()\n",
    "        #df_train_median = df_train.median()\n",
    "        df_train_mean['dataset'] = df_name\n",
    "        df_train_std['dataset'] = df_name\n",
    "        #df_train_median['dataset'] = df_name\n",
    "        df_train_mean['type'] = 'mean'\n",
    "        #df_train_median['type'] = 'median'\n",
    "        df_train_std['type'] = 'std'\n",
    "        perf_train.append(df_train_mean.to_frame().T)\n",
    "        #perf_train.append(df_train_median.to_frame().T)\n",
    "        perf_train.append(df_train_std.to_frame().T)\n",
    "        \n",
    "        df_fair_mean = df_fair.mean()\n",
    "        #df_fair_median = df_fair.median()\n",
    "        df_fair_std = df_fair.std()\n",
    "        df_fair_mean['dataset'] = df_name\n",
    "        #df_fair_median['dataset'] = df_name\n",
    "        df_fair_std['dataset'] = df_name\n",
    "        df_fair_mean['type'] = 'mean'\n",
    "        #df_fair_median['type'] = 'median'\n",
    "        df_fair_std['type'] = 'std'\n",
    "        perf_fair.append(df_fair_mean.to_frame().T)\n",
    "        #perf_fair.append(df_fair_median.to_frame().T)\n",
    "        perf_fair.append(df_fair_std.to_frame().T)\n",
    "    \n",
    "    perf_train = pd.concat(perf_train).reset_index(drop=True)\n",
    "    perf_fair = pd.concat(perf_fair).reset_index(drop=True)\n",
    "    return perf_train, perf_fair"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3bc2e6728c9b446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aggregate_runs(dfs, drop_columns = None):\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.drop(columns=['iteration'], inplace=True)\n",
    "    if drop_columns is not None:\n",
    "        df.drop(columns=drop_columns, inplace=True)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df = df.groupby(['classifier', 'algorithm']).agg(['mean', 'std'])\n",
    "    return df"
   ],
   "id": "9c3cdc3461ca2dd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_to_latex(dfs_f, dfs_p, drop_columns_f=None, drop_columns_p=None):\n",
    "    df_f = aggregate_runs(dfs_f, drop_columns=drop_columns_f)\n",
    "    df_p = aggregate_runs(dfs_p, drop_columns=drop_columns_p)\n",
    "    df = df_f.join(df_p)\n",
    "    print(df.to_latex(index=True,\n",
    "                  float_format=\"{:.4f}\".format,\n",
    "))  "
   ],
   "id": "2976461425016f16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aggregate_runs_c(dfs, drop_columns=None, fair=True):\n",
    "    \"\"\"\n",
    "    Aggregates runs by concatenating DataFrames, dropping specified columns,\n",
    "    taking the absolute value of numerical columns, and calculating mean and\n",
    "    standard deviation grouped by 'classifier' and 'algorithm'.\n",
    "    \"\"\"\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.drop(columns=['iteration'], inplace=True)\n",
    "    if drop_columns is not None:\n",
    "        df.drop(columns=drop_columns, inplace=True)\n",
    "    df['classifier'].replace({'decision_tree': 'Decision Tree', 'logistic_regression': 'Logistic Regression', 'mlp': 'MLP'}, inplace=True)\n",
    "    df['algorithm'].replace({'fair_rbu': 'Fair-RBU', 'fair_rbh': 'Fair-RBH', 'fos': 'FOS', 'fawos': 'FAWOS', 'hfos': 'HFOS'}, inplace=True)\n",
    "    if fair:\n",
    "        df.rename(columns={'statistical_parity': 'SPD', 'average_absolute_odds': 'AAO', 'equal_opportunity': 'EOD'}, inplace=True)\n",
    "        features = ['SPD', 'AAO', 'EOD']\n",
    "    else:\n",
    "        df.rename(columns={'accuracy': 'Accuracy', 'f1': 'F1', 'gmean': 'G-mean'}, inplace=True)\n",
    "        features = ['Accuracy', 'F1', 'G-mean']\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    \n",
    "    grouped = df.groupby(['classifier', 'algorithm']).agg(['mean', 'std'])\n",
    "    \n",
    "    # Combine mean and std into one cell\n",
    "    combined = grouped.copy()\n",
    "    for col in df_num_cols:\n",
    "        combined[(col, 'mean')] = grouped[(col, 'mean')].map('{:.4f}'.format) + ' (\\\\textpm' + grouped[(col, 'std')].map('{:.3f}'.format) + ')'\n",
    "        combined.drop((col, 'std'), axis=1, inplace=True)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def print_to_latex_c(dfs_f, dfs_p, drop_columns_f=None, drop_columns_p=None):\n",
    "    \"\"\"\n",
    "    Aggregates and joins two sets of DataFrames, and prints the resulting\n",
    "    DataFrame to LaTeX format.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_f = aggregate_runs_c(dfs_f, drop_columns=drop_columns_f, fair=True)\n",
    "    \n",
    "    df_p = aggregate_runs_c(dfs_p, drop_columns=drop_columns_p, fair=False)\n",
    "    df = df_f.join(df_p)\n",
    "    \n",
    "    print(df.to_latex(index=True, escape=False))"
   ],
   "id": "dcc4ab4326a715a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def aggregate_runs_no_mean(dfs, fair, dataset_name, bin, save_path='../figures'):\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df['classifier'].replace({'decision_tree': 'Decision Tree', 'logistic_regression': 'Logistic Regression', 'mlp': 'MLP'}, inplace=True)\n",
    "    df['algorithm'].replace({'fair_rbu': 'Fair-RBU', 'fair_rbh': 'Fair-RBH', 'fos': 'FOS', 'fawos': 'FAWOS', 'hfos': 'HFOS'}, inplace=True)\n",
    "    if fair:\n",
    "        df.rename(columns={'statistical_parity': 'SPD', 'average_absolute_odds': 'AAO', 'equal_opportunity': 'EOD'}, inplace=True)\n",
    "        features = ['SPD', 'AAO', 'EOD']\n",
    "    else:\n",
    "        df.rename(columns={'accuracy': 'Accuracy', 'f1': 'F1', 'gmean': 'G-mean'}, inplace=True)\n",
    "        features = ['Accuracy', 'F1', 'G-mean']\n",
    "    df = df.melt(id_vars=['classifier', 'algorithm'], value_vars=features)\n",
    "    df.rename(columns={'variable': 'metric'}, inplace=True)\n",
    "    sns.set(font_scale=0.75) \n",
    "    g = sns.FacetGrid(df, row=\"classifier\", col='metric', row_order=['Decision Tree', 'Logistic Regression', 'MLP'], col_order=features, height=3, aspect=1.25)\n",
    "    g.map_dataframe(sns.boxplot, x='algorithm', y='value', hue='algorithm', palette='colorblind', order=['-', 'FAWOS', 'FOS', 'Fair-RBH', 'Fair-RBU', 'HFOS'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/{dataset_name}_{bin}_results_{fair}.pdf')\n",
    "    plt.show()"
   ],
   "id": "f07ea57737d5e4ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cont ord cat",
   "id": "e72df4c088362dfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dfs_fairness = []\n",
    "dfs_performance = []\n",
    "dataset_names = ['bank']#, 'german', 'adult', 'bank']\n",
    "#dataset_names = ['adult_' + i[:-4] for i in os.listdir('../data/adult_census/sampled_all/new') if '_balanced_g_' not in i]\n",
    "#dataset_names = [d for d in dataset_names if '_balanced_g' not in d]\n",
    "classifier_names = ['decision_tree', 'mlp', 'logistic_regression']\n",
    "algorithm_names = ['fair_rbh', 'fair_rbu', 'fos', 'hfos', 'fawos']# 'fawos_hybrid']\n",
    "#algorithm_names = ['fos']\n",
    "folder_names = ['2024-07-14', '2024-07-14', '2024-06-29', '2024-06-29', '2024-06-29', '2024-08-24']\n",
    "#folder_names = ['all_cont']\n",
    "main_path = '../results'\n",
    "\n",
    "print(dataset_names)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    df_data_fair = []\n",
    "    df_data_perf = []\n",
    "    for classifier_name in classifier_names:\n",
    "        for folder_name, algorithm_name in zip(folder_names, algorithm_names):\n",
    "            for i in range(0, 10):\n",
    "                if os.path.exists(os.path.join(main_path, f'{algorithm_name}_{dataset_name}_{classifier_name}', folder_name, f'fairness_{i}.csv')):\n",
    "                    fair_path = os.path.join(main_path, f'{algorithm_name}_{dataset_name}_{classifier_name}', folder_name, f'fairness_{i}.csv')\n",
    "                    perf_path = os.path.join(main_path, f'{algorithm_name}_{dataset_name}_{classifier_name}', folder_name, f'performance_{i}.csv')\n",
    "                    df_fair = pd.read_csv(fair_path)\n",
    "                    df_performance = pd.read_csv(perf_path)\n",
    "                    df_fair['classifier'] = [classifier_name] * len(df_fair)\n",
    "                    df_fair['algorithm'] = [f'{algorithm_name}' if 'fair' in x else '-' for x in df_fair['data']]\n",
    "                    df_fair['iteration'] = [i] * len(df_fair)\n",
    "                    # df_fair.drop(columns=['data', 'average_odds', 'average_absolute_odds'], inplace=True)\n",
    "                    df_fair.drop(columns=['data'], inplace=True)\n",
    "                    df_performance['classifier'] = [classifier_name] * len(df_performance)\n",
    "                    df_performance['algorithm'] = [f'{algorithm_name}' if 'fair' in x else '-' for x in df_performance['data']]\n",
    "                    df_performance['iteration'] = [i] * len(df_performance)\n",
    "                    df_performance.drop(columns=['data'], inplace=True)\n",
    "                    df_data_fair.append(df_fair)\n",
    "                    df_data_perf.append(df_performance)\n",
    "    dfs_fairness.append(df_data_fair)\n",
    "    dfs_performance.append(df_data_perf)\n",
    "                "
   ],
   "id": "75cc1e7e10ac0612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_fairness):\n",
    "    df = aggregate_runs(dfs, drop_columns=['accuracy', 'disparate_impact', 'average_odds', ])\n",
    "    print(dataset_name)\n",
    "    display(df)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "44921e2a08ee188d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs_f, dfs_p in zip(dataset_names, dfs_fairness, dfs_performance):\n",
    "    df = aggregate_runs(dfs_p, drop_columns=['balanced_accuracy',])\n",
    "    print(dataset_name)\n",
    "    display(df)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "3c74eaf68585e3ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs_f, dfs_p in zip(dataset_names, dfs_fairness, dfs_performance):\n",
    "    print(dataset_name)\n",
    "    print_to_latex_c(dfs_f, dfs_p, drop_columns_f=['accuracy', 'disparate_impact', 'average_odds', 'adapted_disparate_impact'], drop_columns_p=['balanced_accuracy',])\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "93d2d318ae6507de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for dataset_name, dfs in zip(dataset_names, dfs_performance):\n",
    "    print(dataset_name)\n",
    "    print_to_latex(dfs)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "87445a71c25cc377",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_fairness):\n",
    "    print(dataset_name)\n",
    "    aggregate_runs_no_mean(dfs, True, dataset_name, 'bin')"
   ],
   "id": "87d5cdd817fab7e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_performance):\n",
    "    print(dataset_name)\n",
    "    aggregate_runs_no_mean(dfs, False, dataset_name, 'bin')"
   ],
   "id": "984f5b9dceb1cd37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aggregate_runs_no_mean(dfs_f, dfs_p, dataset_name, bin, save_path='../figures'):\n",
    "    \n",
    "    df = pd.concat(dfs_f).reset_index(drop=True).drop(columns=['accuracy'])\n",
    "    df1 = pd.concat(dfs_p).reset_index(drop=True)\n",
    "    df = df.set_index(['classifier', 'algorithm', 'iteration']).join(df1.set_index(['classifier', 'algorithm', 'iteration']))\n",
    "    df = df.reset_index(drop=False)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df['classifier'].replace({'decision_tree': 'Decision Tree', 'logistic_regression': 'Logistic Regression', 'mlp': 'MLP'}, inplace=True)\n",
    "    df['algorithm'].replace({'fair_rbu': 'Fair-RBU', 'fair_rbh': 'Fair-RBH', 'fos': 'FOS', 'fawos': 'FAWOS', 'hfos': 'HFOS'}, inplace=True)\n",
    "    \n",
    "    df.rename(columns={'statistical_parity': 'SPD', 'average_absolute_odds': 'AAO', 'equal_opportunity': 'EOD'}, inplace=True)\n",
    "    df.rename(columns={'accuracy': 'Accuracy', 'f1': 'F1', 'gmean': 'G-mean'}, inplace=True)\n",
    "    features = ['SPD', 'EOD','AAO', 'Accuracy', 'F1', 'G-mean']\n",
    "    df = df.melt(id_vars=['classifier', 'algorithm'], value_vars=features)\n",
    "    df.rename(columns={'variable': 'metric'}, inplace=True)\n",
    "    sns.set(font_scale=0.75, style='whitegrid') \n",
    "    g = sns.FacetGrid(df, row=\"classifier\", col='metric', row_order=['Decision Tree', 'Logistic Regression', 'MLP'], col_order=features, height=3, aspect=1.25, margin_titles=True, despine=False, sharey=True)\n",
    "    g.map_dataframe(sns.boxplot, x='algorithm', y='value', hue='algorithm', palette='colorblind', order=['-', 'FAWOS', 'FOS', 'Fair-RBH', 'Fair-RBU', 'HFOS'], showmeans=True, meanprops={\"marker\": \"^\", \"markerfacecolor\": \"black\", 'markeredgecolor': 'black'}, hue_order=['-','Fair-RBH', 'Fair-RBU', 'FAWOS', 'FOS', 'HFOS'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/{dataset_name}_{bin}_results.pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name, dfs_f, dfs_p in zip(dataset_names, dfs_fairness, dfs_performance):\n",
    "    print(dataset_name)\n",
    "    \n",
    "    aggregate_runs_no_mean(dfs_f, dfs_p, dataset_name, 'bin')"
   ],
   "id": "e37cadc6bc1b8912",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def construct_big_df(dfs, dataset_names, bin):\n",
    "    dfs_new = []\n",
    "    if bin:\n",
    "        dict_ratios = {'_balanced_g': '1:1', 'mildly_imbalanced_g': '7:3', 'strongly_imbalanced_g': '9:1', \n",
    "                       '_balanced_c': '1:1', 'mildly_imbalanced_c': '7:3', 'strongly_imbalanced_c': '9:1'}\n",
    "    else:\n",
    "        dict_ratios = {'_balanced_g': '1:1:1:1', 't_mildly_imbalanced_g': '7:7:3:3', 't_strongly_imbalanced_g': '9:9:1:1', 't_strongly_mildly_imbalanced_g': '9:7:3:1',\n",
    "                       '_balanced_c': '1:1', 'g_mildly_imbalanced_c': '7:3', 'g_strongly_imbalanced_c': '9:1', }\n",
    "    for df, d_name in zip(dfs, dataset_names):\n",
    "        g_imbalance = [dict_ratios[i] for i in dict_ratios.keys() if i in d_name and '_g' in i][0]\n",
    "        c_imbalance = [dict_ratios[i] for i in dict_ratios.keys() if i in d_name and '_c' in i][0]\n",
    "        print(d_name, g_imbalance, c_imbalance)\n",
    "        df_whole = pd.concat(df).reset_index(drop=True)\n",
    "        df_whole['group ratio'] = [g_imbalance] * len(df_whole)\n",
    "        df_whole['class ratio'] = [c_imbalance] * len(df_whole)\n",
    "        dfs_new.append(df_whole)\n",
    "    big_df = pd.concat(dfs_new).reset_index(drop=True)\n",
    "    return big_df\n",
    "\n",
    "def aggregate_runs_no_mean_adult(df, column_to_use, classifier, bin, save_path='../figures'):\n",
    "    \n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm', 'group ratio', 'class ratio']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df['classifier'].replace({'decision_tree': 'Decision Tree', 'logistic_regression': 'Logistic Regression', 'mlp': 'MLP'}, inplace=True)\n",
    "    df['algorithm'].replace({'fair_rbu': 'Fair-RBU', 'fair_rbh': 'Fair-RBH', 'fos': 'FOS', 'fawos': 'FAWOS', 'hfos': 'HFOS'}, inplace=True)\n",
    "    df = df.loc[df['classifier'] == classifier, :]\n",
    "    df.drop(columns=['classifier'], inplace=True)\n",
    "    try:\n",
    "        df.rename(columns={'statistical_parity': 'SPD', 'average_absolute_odds': 'AAO', 'equal_opportunity': 'EOD'}, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df.rename(columns={'accuracy': 'Accuracy', 'f1': 'F1', 'gmean': 'G-mean'}, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    features = [column_to_use]\n",
    "    df_drop_columns = [c for c in df.columns if c not in ['classifier', 'algorithm', 'group ratio', 'class ratio', 'iteration', column_to_use]]\n",
    "    df.drop(columns=df_drop_columns, inplace=True)\n",
    "    #df = df.melt(id_vars=['group_imbalance', 'class_imbalance', 'algorithm'], value_vars=features)\n",
    "    #df.rename(columns={'variable': column_to_use}, inplace=True)\n",
    "    sns.set(font_scale=0.75, style='whitegrid') \n",
    "    g = sns.FacetGrid(df, row=\"class ratio\", col='group ratio', row_order=['1:1', '7:3', '9:1'], col_order=['1:1', '7:3', '9:1'], height=3, aspect=1.25, margin_titles=True, despine=False)\n",
    "    g.map_dataframe(sns.boxplot, x='algorithm', y=column_to_use, hue='algorithm', palette='colorblind', order=['-', 'FAWOS', 'FOS', 'Fair-RBH', 'Fair-RBU', 'HFOS'], showmeans=True, meanprops={\"marker\": \"^\", \"markerfacecolor\": \"black\", 'markeredgecolor': 'black'}, hue_order=['-','Fair-RBH', 'Fair-RBU', 'FAWOS', 'FOS', 'HFOS'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/adult_imbalances_{bin}_results_{column_to_use}_{classifier}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def aggregate_runs_no_mean_adult_multi(df, column_to_use, classifier, bin, save_path='../figures'):\n",
    "    \n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm', 'group ratio', 'class ratio']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df['classifier'].replace({'decision_tree': 'Decision Tree', 'logistic_regression': 'Logistic Regression', 'mlp': 'MLP'}, inplace=True)\n",
    "    df['algorithm'].replace({'fair_rbu': 'Fair-RBU', 'fair_rbh': 'Fair-RBH', 'fos': 'FOS', 'fawos': 'FAWOS', 'hfos': 'HFOS'}, inplace=True)\n",
    "    df = df.loc[df['classifier'] == classifier, :]\n",
    "    df.drop(columns=['classifier'], inplace=True)\n",
    "    try:\n",
    "        df.rename(columns={'statistical_parity': 'SPD', 'average_absolute_odds': 'AAO', 'equal_opportunity': 'EOD'}, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df.rename(columns={'accuracy': 'Accuracy', 'f1': 'F1', 'gmean': 'G-mean'}, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    features = [column_to_use]\n",
    "    df_drop_columns = [c for c in df.columns if c not in ['classifier', 'algorithm', 'group ratio', 'class ratio', 'iteration', column_to_use]]\n",
    "    df.drop(columns=df_drop_columns, inplace=True)\n",
    "    #df = df.melt(id_vars=['group_imbalance', 'class_imbalance', 'algorithm'], value_vars=features)\n",
    "    #df.rename(columns={'variable': column_to_use}, inplace=True)\n",
    "    sns.set(font_scale=0.75, style='whitegrid') \n",
    "    print(df)\n",
    "    g = sns.FacetGrid(df, row=\"class ratio\", col='group ratio', row_order=['1:1', '7:3', '9:1'], col_order=['7:7:3:3', '9:7:3:1', '9:9:1:1'], height=3, aspect=1.25, margin_titles=True, despine=False)\n",
    "    g.map_dataframe(sns.boxplot, x='algorithm', y=column_to_use, hue='algorithm', palette='colorblind', order=['-', 'FAWOS', 'Fair-RBH', 'Fair-RBU', 'HFOS'], showmeans=True, meanprops={\"marker\": \"^\", \"markerfacecolor\": \"black\", 'markeredgecolor': 'black'}, hue_order=['-','Fair-RBH', 'Fair-RBU', 'FAWOS', 'FOS', 'HFOS'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/adult_imbalances_{bin}_results_{column_to_use}_{classifier}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "whole_dataset = construct_big_df(dfs_performance, dataset_names, False)\n",
    "for cls in ['Decision Tree', 'Logistic Regression', 'MLP']:\n",
    "    aggregate_runs_no_mean_adult_multi(whole_dataset, 'G-mean', cls, False)"
   ],
   "id": "c855a5d1fb35cc2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "54c693a49c5214e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
