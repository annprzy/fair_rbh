{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_all_csvs(main_path, dataset_names, classifier_names, algorithm_names, date):\n",
    "    dfs_fairness = []\n",
    "    dfs_performance = []\n",
    "    \n",
    "    for dataset_name in dataset_names:\n",
    "        df_data_fair = []\n",
    "        df_data_perf = []\n",
    "        for classifier_name in classifier_names:\n",
    "            for algorithm_name in algorithm_names:\n",
    "                folder_path = os.path.join(main_path, f'{algorithm_name}_{dataset_name}_{classifier_name}')\n",
    "                folders_inside_folder = [f for f in os.listdir(folder_path) if 'hvdm' in f] #'heom' in f and '_1' not in f and '_2' not in f and '_3' not in f and '_4' not in f]\n",
    "                #print(folders_inside_folder)\n",
    "                folders_inside_folder = [f for f in os.listdir(os.path.join(folder_path, 'hvdm'))]\n",
    "                for folder_name in folders_inside_folder:\n",
    "                    if algorithm_name in ['fawos', 'hfos', 'fos']:\n",
    "                        # f = [f for f in os.listdir(os.path.join(folder_path, folder_name)) if \"5\" in f ][0]\n",
    "                        # print(f)\n",
    "                        folder_name = os.path.join('hvdm', folder_name)\n",
    "                        #folder_name = os.path.join(folder_name, f)\n",
    "                    for i in range(0, 5):\n",
    "                        if os.path.exists(os.path.join(folder_path, folder_name, date, f'fairness_{i}.csv')):\n",
    "                            fair_path = os.path.join(folder_path, folder_name, date, f'fairness_{i}.csv')\n",
    "                            perf_path = os.path.join(folder_path, folder_name, date, f'performance_{i}.csv')\n",
    "                            df_fair = pd.read_csv(fair_path)\n",
    "                            df_performance = pd.read_csv(perf_path)\n",
    "                            df_fair['classifier'] = [classifier_name] * len(df_fair)\n",
    "                            df_fair['algorithm'] = [algorithm_name if 'fair' in x else '-' for x in df_fair['data']]\n",
    "                            df_fair['iteration'] = [i] * len(df_fair)\n",
    "                            df_fair['params'] = [folder_name if 'fair' in x else '-' for x in df_fair['data']]\n",
    "                            # df_fair.drop(columns=['data', 'average_odds', 'average_absolute_odds'], inplace=True)\n",
    "                            df_fair.drop(columns=['data'], inplace=True)\n",
    "                            df_performance['classifier'] = [classifier_name] * len(df_performance)\n",
    "                            df_performance['algorithm'] = [algorithm_name if 'fair' in x else '-' for x in df_performance['data']]\n",
    "                            df_performance['iteration'] = [i] * len(df_performance)\n",
    "                            df_performance['params'] = [folder_name if 'fair' in x else '-' for x in df_performance['data']]\n",
    "                            df_performance.drop(columns=['data'], inplace=True)\n",
    "                            df_data_fair.append(df_fair)\n",
    "                            df_data_perf.append(df_performance)\n",
    "        dfs_fairness.append(df_data_fair)\n",
    "        dfs_performance.append(df_data_perf)\n",
    "    return dfs_fairness, dfs_performance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aggregate_runs(dfs):\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.drop(columns=['iteration'], inplace=True)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm', 'params']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df = df.groupby(['classifier', 'algorithm', 'params']).agg(['mean', 'std'])\n",
    "    return df"
   ],
   "id": "41646682dabc2b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aggregate_everything(dfs):\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.drop(columns=['iteration', 'classifier', 'algorithm'], inplace=True)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['params']]\n",
    "    df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    df = df.groupby(['params']).agg(['mean', 'std'])\n",
    "    return df"
   ],
   "id": "30b343f559bdae15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def aggregate_runs_no_mean(dfs, y):\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df_num_cols = [c for c in df.columns if c not in ['classifier', 'algorithm', 'params']]\n",
    "    #df.loc[:, df_num_cols] = df.loc[:, df_num_cols].abs()\n",
    "    g = sns.FacetGrid(df, col=\"classifier\")\n",
    "    g.map_dataframe(sns.lineplot, x='iteration', y=y, hue='params', errorbar=None)\n",
    "    g.add_legend()\n",
    "    plt.show()"
   ],
   "id": "687c3c1302d5c084",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "main_paths = ['../validation', '../validation_multi']\n",
    "datasets_names = [['german', 'heart_disease', 'adult', 'bank'], ['adult', 'german', 'bank']]\n",
    "classifier_names = ['logistic_regression', 'mlp', 'decision_tree']\n",
    "algorithm_names = ['hfos']\n",
    "date = '2024-06-12'\n",
    "\n",
    "df_sums_aao, df_sums_p = [], []\n",
    "all_df_sums = []\n",
    "for main_path, dataset_names in zip(main_paths, datasets_names):\n",
    "    dfs_fairness, dfs_performance = read_all_csvs(main_path, dataset_names, classifier_names, algorithm_names, date)\n",
    "    df_sums_aao_one = []\n",
    "    df_sums_p_one = []\n",
    "    all_df_sums0 = []\n",
    "    for dataset_name, dfs_f, dfs_p in zip(dataset_names, dfs_fairness, dfs_performance):\n",
    "        #display(aggregate_runs(dfs_f))\n",
    "        df_f = aggregate_everything(dfs_f)\n",
    "        df_p = aggregate_everything(dfs_p)\n",
    "        \n",
    "        df_sums1 = pd.concat(dfs_f).reset_index(drop=True)[['iteration', 'classifier', 'algorithm', 'params', 'average_absolute_odds']]\n",
    "        df_sums1 = df_sums1[df_sums1['algorithm'] != '-']\n",
    "        #print(df_sums1)\n",
    "        df_sums1.set_index(['iteration', 'classifier', 'algorithm', 'params'], inplace=True)\n",
    "        df_sums2 = pd.concat(dfs_p).reset_index(drop=True)[['iteration', 'classifier', 'algorithm', 'params', 'gmean']]\n",
    "        df_sums2 = df_sums2[df_sums2['algorithm'] != '-']\n",
    "        df_sums2.set_index(['iteration', 'classifier', 'algorithm', 'params'], inplace=True)\n",
    "        df_sums = df_sums1.join(df_sums2)\n",
    "        df_sums['score'] = ((1 - df_sums1['average_absolute_odds']) * df_sums2['gmean']) ** 0.5\n",
    "        df_sums.reset_index(inplace=True)\n",
    "        df_sums.drop(columns=['average_absolute_odds', 'gmean', 'iteration', 'classifier', 'algorithm'], inplace=True)\n",
    "        df_sums.set_index('params', inplace=True)\n",
    "        all_df_sums0.append(df_sums)\n",
    "        all_df_sums.append(df_sums)\n",
    "        \n",
    "        print(dataset_name)\n",
    "        display(df_f)\n",
    "        display(df_p)\n",
    "        df_sum = ((1 - df_f[('average_absolute_odds', 'mean')].abs()) * df_p[('gmean', 'mean')]) ** 0.5\n",
    "        df_sums_aao.append(df_f[('average_absolute_odds', 'mean')].abs())\n",
    "        df_sums_p.append(df_p[('gmean', 'mean')])\n",
    "        df_sums_aao_one.append(df_f[('average_absolute_odds', 'mean')].abs())\n",
    "        df_sums_p_one.append(df_p[('gmean', 'mean')])\n",
    "        #print(df_sum)\n",
    "        print('-- overall score')\n",
    "        display(df_sums.groupby(['params']).mean())\n",
    "        print('----------------------------------------------------------------')\n",
    "    #df_sum = ((1 - pd.concat(df_sums_aao_one, axis=1).agg(['mean'], axis=1)) * pd.concat(df_sums_p_one, axis=1).agg(['mean'], axis=1)) ** 0.5\n",
    "    print(pd.concat(df_sums_aao_one, axis=1).agg(['mean'], axis=1))\n",
    "    print(pd.concat(df_sums_p_one, axis=1).agg(['mean'], axis=1))\n",
    "    \n",
    "    display(pd.concat(all_df_sums0, axis=0).groupby(['params']).mean())\n",
    "    #print(df_sum)\n",
    "    print('=============================================================================================')\n",
    "print('Overall')\n",
    "df_sum = ((1 - pd.concat(df_sums_aao, axis=1).agg(['mean'], axis=1)) * pd.concat(df_sums_p, axis=1).agg(['mean'], axis=1)) ** 0.5\n",
    "\n",
    "\n",
    "#print(df_sums)\n",
    "print(pd.concat(df_sums_aao, axis=1).agg(['mean'], axis=1))\n",
    "print(pd.concat(df_sums_p, axis=1).agg(['mean'], axis=1))\n",
    "print(df_sum)\n",
    "\n",
    "display(pd.concat(all_df_sums, axis=0).groupby(['params']).mean())"
   ],
   "id": "e063e26f33d41596",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_sums_aao = []\n",
    "df_sums_p = []\n",
    "for dataset_name, dfs_f, dfs_p in zip(dataset_names, dfs_fairness, dfs_performance):\n",
    "    df_f = aggregate_everything(dfs_f)\n",
    "    df_p = aggregate_everything(dfs_p)\n",
    "    print(dataset_name)\n",
    "    display(df_f)\n",
    "    display(df_p)\n",
    "    df_sum = ((1 - df_f[('average_absolute_odds', 'mean')].abs()) * df_p[('gmean', 'mean')]) ** 0.5\n",
    "    df_sums_aao.append(df_f[('average_absolute_odds', 'mean')].abs())\n",
    "    df_sums_p.append(df_p[('gmean', 'mean')])\n",
    "    print(df_sum)\n",
    "    print('----------------------------------------------------------------')\n",
    "df_sum = ((1 - pd.concat(df_sums_aao, axis=1).agg(['mean'], axis=1)) * pd.concat(df_sums_p, axis=1).agg(['mean'], axis=1)) ** 0.5\n",
    "print(pd.concat(df_sums_aao, axis=1).agg(['mean'], axis=1))\n",
    "print(pd.concat(df_sums_p, axis=1).agg(['mean'], axis=1))\n",
    "print(df_sum)"
   ],
   "id": "cb65d5166cc68947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_performance):\n",
    "    df = aggregate_everything(dfs)\n",
    "    print(dataset_name)\n",
    "    display(df)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "621e0c6ace9e66f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_fairness):\n",
    "    df = aggregate_runs(dfs)\n",
    "    print(dataset_name)\n",
    "    display(df)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "4f7a543626bc97b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_performance):\n",
    "    df = aggregate_runs(dfs)\n",
    "    print(dataset_name)\n",
    "    display(df)\n",
    "    print('----------------------------------------------------------------')"
   ],
   "id": "c489d073347b4f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dfs in zip(dataset_names, dfs_fairness):\n",
    "    print(dataset_name)\n",
    "    aggregate_runs_no_mean(dfs, y='statistical_parity')"
   ],
   "id": "bd9d9d1285f083d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ec8d261024fcb0e6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
